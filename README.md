# ğŸ•·ï¸ MySQL Database Crawler & Model Generator (Java + Spring Boot)

## ğŸ“˜ Overview
This project is a **Database Crawler** built with **Java and Spring Boot** that connects to a MySQL database, extracts its schema metadata (tables, columns, keys, relationships), and **automatically generates Java model classes** dynamically at runtime using **ByteBuddy**.

It provides **REST APIs** to:
- Extract database schema metadata  
- Generate Java model classes programmatically  

---

## ğŸš€ Features

âœ… Connects to any MySQL database via JDBC  
âœ… Crawls database schema (tables, columns, keys, indexes, relationships)  
âœ… Dynamically generates Java model classes at runtime  
âœ… Provides REST APIs for metadata extraction and model generation  
âœ… Supports easy configuration using a JSON file  
âœ… Modular architecture (Controller, Service, Model layers)  

---

## ğŸ§© Technologies Used

| Component | Technology |
|------------|-------------|
| Language | Java 17 |
| Framework | Spring Boot 3.x |
| Database | MySQL |
| ORM / Runtime Generation | ByteBuddy |
| API Tool | Postman |
| Build Tool | Maven |

---

## ğŸ—‚ï¸ Project Structure

src/
â”œâ”€â”€ main/
â”‚ â”œâ”€â”€ java/com/grafyn/assignment/
â”‚ â”‚ â”œâ”€â”€ controller/ # REST Controllers
â”‚ â”‚ â”œâ”€â”€ service/ # Crawler & Model generation logic
â”‚ â”‚ â”œâ”€â”€ model/ # Schema representation models
â”‚ â”‚ â””â”€â”€ Application.java # Spring Boot main class
â”‚ â””â”€â”€ resources/
â”‚ â”œâ”€â”€ application.properties
â”‚ â””â”€â”€ crawler-config.json # JSON configuration for DB connection
â””â”€â”€ test/ # (Optional) Unit tests

yaml
Copy code

---

## âš™ï¸ Configuration

Edit the file:  
`src/main/resources/crawler-config.json`

```json
{
  "host": "localhost",
  "port": 3306,
  "username": "root",
  "password": "yourpassword",
  "schema": "mydb"
}
This file tells the crawler which database to connect to.
You can switch databases simply by changing these values â€” no code changes needed.

ğŸ”Œ REST API Endpoints
1ï¸âƒ£ Extract Schema Metadata
Endpoint:


GET /api/schema/
Description:
Fetches all database metadata such as tables, columns, primary keys, foreign keys, and indexes.

Sample Response:

json
{
  "schemaName": "mydb",
  "tables": {
    "stud": {
      "columns": {
        "id": {"jdbcType": "INT", "nullable": false},
        "name": {"jdbcType": "VARCHAR", "nullable": true},
        "age": {"jdbcType": "INT", "nullable": false}
      },
      "primaryKeys": ["id"],
      "foreignKeys": [],
      "indexes": [{"indexName": "PRIMARY", "columnName": "id"}]
    }
  }
}
2ï¸âƒ£ Generate Java Models
Endpoint:

bash
Copy code
POST /api/schema/generate
Description:
Takes the JSON output from /api/schema/ and generates corresponding Java classes dynamically at runtime.

Sample Response:

json
Copy code
{
  "generatedCount": 1,
  "classNames": ["com.example.models.Stud"]
}
ğŸ§  How It Works (Architecture)
The crawler connects to the MySQL database using JDBC.

It extracts metadata via DatabaseMetaData API (tables, columns, keys, etc.).

The metadata is stored in an internal schema object.

On calling /api/schema/generate, the metadata is passed to ByteBuddy, which generates corresponding Java model classes dynamically.

The generated classes represent tables and relationships, ready to be used by any application layer.

ğŸ§° Run the Project
Prerequisites
Java 17+

Maven 3+

MySQL server running

Database configured in crawler-config.json

Steps
bash
# Clone this repository
git clone https://github.com/<your-username>/mysql-schema-crawler.git

# Navigate into the project
cd mysql-schema-crawler

# Build and run the project
mvn spring-boot:run
ğŸ” Testing the APIs
You can test using Postman or curl:

<pre> ```bash # Extract schema GET http://localhost:8080/api/schema/ ``` </pre>

# Generate models
POST http://localhost:8080/api/schema/generate
ğŸ§± Sample Output
pgsql
Copy code
âœ… Loaded configuration from: src/main/resources/crawler-config.json
âœ… Connected to database: mydb
âœ… Extracted 1 tables
âœ… Generated 1 model class: com.example.models.Stud
ğŸ“˜ Documentation
The documentation explains:

Architecture and workflow

Schema extraction process

Model generation flow

Sample API outputs

ğŸ’¬ Author
ğŸ‘¤ Vishal Uttam Palve
ğŸ“§ vishalxpalve@gmail.com

ğŸ§¾ License
This project is developed as part of an assignment for Vistora.
All rights reserved Â© 2025 Vishal Palve.


---

âœ… This version will render cleanly on GitHub â€”  
no red, no broken sections, and all code blocks will format correctly.  

Would you like me to also include a **â€œSetup Verificationâ€** section next (to test DB connectivity b
